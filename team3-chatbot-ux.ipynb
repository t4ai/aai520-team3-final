{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Generative Q&A Chatbot Using distilBERT model - UX Frontend using Gradio and hosted on Hugging Face Spaces\n",
    "## AAI-520 Team 3 Final Project\n",
    "\n",
    "Team 3 Members:  Tyler Foreman, Ahmed Ahmed, Tursun Alkam\n",
    "\n",
    "Date:  October 23, 2023\n",
    "\n",
    "GitHub Repository: https://github.com/t4ai/aai520-team3-final\n",
    "\n",
    "Live hosted version: https://huggingface.co/spaces/t4ai/T3Soft-QA-Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import gradio as gr\n",
    "import random \n",
    "import time \n",
    "import requests\n",
    "\n",
    "from transformers import BertModel, BertTokenizerFast, AdamW\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load API key\n",
    "load_dotenv(override=True)\n",
    "if not os.getenv(\"HF_API_KEY\"):\n",
    "    raise ValueError(\"HF_API_KEY must be set\")\n",
    "hf_key = os.getenv('HF_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model inference API with authorization token\n",
    "API_URL = \"https://api-inference.huggingface.co/models/t4ai/distilbert-finetuned-t3-qa\"\n",
    "headers = {\"Authorization\": \"Bearer \" + hf_key }\n",
    "\n",
    "# helper function to call inference API and return response\n",
    "def query_model(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9349796772003174, 'start': 17, 'end': 21, 'answer': 'John'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_model({\"inputs\": {\"question\": \"what is my name?\", \"context\": \"hello my name is John and I live in San Francisco\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build UI Using Gradio for hosting on HuggingFace Spaces\n",
    "\n",
    "Leverage gradio components to construct a chatbot interface along with location to input context/document text.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7898\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7898/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contruct UI using Gradio\n",
    "_booted = False\n",
    "with gr.Blocks() as demo:\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            context = gr.Textbox(label=\"Document Text\", lines=25)\n",
    "        with gr.Column(scale=2):\n",
    "            chatbot = gr.Chatbot(label=\"T3Soft Bot\", value=[(None, \"Welcome! I am your QA assistant.\"), (None, \"Please paste your document content in the panel to the left.\"), (None, \"Then submit questions below!\")])\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=6):\n",
    "                    msg = gr.Textbox(label=\"Ask your question\")            \n",
    "                with gr.Column(scale=1):\n",
    "                    gr.Button(\"Send\")\n",
    "            clear = gr.ClearButton([msg, chatbot])\n",
    "    \n",
    "    def respond(message, context, chat_history):\n",
    "        \n",
    "        if(len(context) == 0):\n",
    "            bot_message = \"Hm, I don't see any document text, please paste in the box on the left.\"\n",
    "        else:    \n",
    "            query_bot = query_model({\"inputs\": {\"question\": message, \"context\": context}})\n",
    "            if(len(query_bot) and (\"answer\" in query_bot)) and (query_bot['score'] > 0.1):\n",
    "                bot_message = query_bot['answer'] + '(' + str(round(query_bot['score'], 2)) + ')'\n",
    "            else:\n",
    "                #bot_message = \"I'm having trouble with this question, please try rewording.\"\n",
    "                bot_message = random.choice([\"I'm having trouble with this question, please try rewording and make sure it is relevant to the document.\", \"Hm, I'm having trouble finding the answer to that.  Can you reword the question?\", \"Sorry, I can't find the answer to this question.\"])\n",
    "        \n",
    "        \n",
    "        chat_history.append((message, bot_message))\n",
    "        time.sleep(2)\n",
    "        return \"\", context, chat_history\n",
    "\n",
    "    msg.submit(respond, [msg, context, chatbot], [msg, context, chatbot])\n",
    "\n",
    "demo.launch()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
